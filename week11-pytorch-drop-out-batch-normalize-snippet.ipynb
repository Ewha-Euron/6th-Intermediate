{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T10:36:06.327729Z","iopub.execute_input":"2024-05-20T10:36:06.328572Z","iopub.status.idle":"2024-05-20T10:36:07.521714Z","shell.execute_reply.started":"2024-05-20T10:36:06.328530Z","shell.execute_reply":"2024-05-20T10:36:07.520310Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\nsubmission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:37:47.488634Z","iopub.execute_input":"2024-05-20T10:37:47.489172Z","iopub.status.idle":"2024-05-20T10:37:47.536875Z","shell.execute_reply.started":"2024-05-20T10:37:47.489140Z","shell.execute_reply":"2024-05-20T10:37:47.535507Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.classifier = nn.Sequential(\n            #1st Hidden Layer\n            nn.Linear(5, 128), \n            #입력 텐서의 크기가 5, 출력 텐서의 크기가 128인 모듈 생성 \n            #Batch Normalization between 'Layer' and 'Activation function'\n            nn.BatchNorm1d(128), \n            #입력이 128 크기, 배치 정규화 수행\n            nn.ReLU(), \n            #ReLU 함수를 활성화함수로 사용!\n            #Drop out after 'Activation function'\n            nn.Dropout(0.1), \n            #드롭 아웃 진행!\n            \n            #2nd Hidden Layer\n            nn.Linear(128, 256), \n            #위에서 출력 텐서 크기가 128, 그래서 이번 층은 입력 텐서 크기가 128\n            nn.BatchNorm1d(256), \n            #출력 텐서 크기를 256으로 지정 -> 파라미터 256으로 설정 후 배치 정규화 수행\n            nn.ReLU(), \n            nn.Dropout(0.1), \n            \n            #3rd Hidden Layer\n            nn.Linear(256, 128), \n            nn.BatchNorm1d(128), \n            nn.ReLU(), \n            nn.Dropout(0.1), \n            \n            #Output Layer\n            nn.Linear(128, 1), \n            nn.Sigmoid()\n        )\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:38:15.587062Z","iopub.execute_input":"2024-05-20T10:38:15.587455Z","iopub.status.idle":"2024-05-20T10:38:15.598774Z","shell.execute_reply.started":"2024-05-20T10:38:15.587425Z","shell.execute_reply":"2024-05-20T10:38:15.597395Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_set = pd.concat((train.drop(['Survived'], axis = 1), test), axis = 0)\n\ndata_set = data_set.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis = 1)\ndata_set = data_set.fillna(data_set.mean())\n\nn_train = train.shape[0]\ntrain_x, test_x = data_set[:n_train], data_set[n_train:]\ntrain_y = train['Survived']\n\ntrain_x = train_x[train_x.keys()].values\ntest_x = test_x[test_x.keys()].values\ntrain_y = train_y.values\n\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nsimple_nn = SimpleNN()\noptimizer = optim.Adam(simple_nn.parameters(), lr = 0.01)\n#Adam 옵티마이저 사용, 학습률 0.01 \nerror = nn.BCELoss()\n#error는 Binary Cross Entropy!\n\nbatch_size = 99\nbatch_count = int(len(train_x)/batch_size)  \n#미니 배치의 수를 batch_count에 저장\n\nfor epoch in range(300):\n    train_loss = 0\n    num_right = 0\n    for i in range(batch_count):\n        start = i*batch_size\n        #미니 배치가 시작되는 인덱스\n        end = start + batch_size\n        #미니 배치의 마자막 데이터 인덱스\n        tensor_x = torch.FloatTensor(train_x[start:end])\n        tensor_y = torch.FloatTensor(train_y[start:end]).reshape(-1, 1)\n        #i 번째 미니 배치에 대한 x, y데이터 생성, y의 경우 reshape로 확실하게 크기 지정 \n        \n        optimizer.zero_grad()\n        #그래디언트 초기화\n        output = simple_nn(tensor_x)\n        #층의 출력값\n        loss = error(output, tensor_y)\n        loss.backward()\n        #역전파 \n        optimizer.step()\n        #가중치 업데이트 \n        \n        train_loss += loss.item() * batch_size\n        #학습 오차를 미니배치에 따라 더해감 \n        result = [1 if out >= 0.5 else 0 for out in output]\n        #output 값의 임곗값을 0.5로 두고 그 이상이면 1, 미만이면 0을 반환\n        num_right += np.sum(np.array(result) == train_y[start:end])\n    train_loss = train_loss / len(train_x)\n    accuracy = num_right / len(train_x)\n    \n    if epoch % 25 == 0:\n        print('Loss: {} Accuracy: {}% Epoch:{}'.format(train_loss, accuracy, epoch))\n        \nprint('Training Ended')","metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:38:33.799827Z","iopub.execute_input":"2024-05-20T10:38:33.800282Z","iopub.status.idle":"2024-05-20T10:38:51.533607Z","shell.execute_reply.started":"2024-05-20T10:38:33.800245Z","shell.execute_reply":"2024-05-20T10:38:51.532401Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Loss: 0.6525094244215224 Accuracy: 0.6386083052749719% Epoch:0\nLoss: 0.5250979165236155 Accuracy: 0.7575757575757576% Epoch:25\nLoss: 0.47150171796480816 Accuracy: 0.7856341189674523% Epoch:50\nLoss: 0.3945884903271993 Accuracy: 0.8170594837261503% Epoch:75\nLoss: 0.355927179257075 Accuracy: 0.8361391694725028% Epoch:100\nLoss: 0.3714137176672618 Accuracy: 0.8294051627384961% Epoch:125\nLoss: 0.3206174754434162 Accuracy: 0.8507295173961841% Epoch:150\nLoss: 0.2851562119192547 Accuracy: 0.8810325476992144% Epoch:175\nLoss: 0.27909259498119354 Accuracy: 0.8799102132435466% Epoch:200\nLoss: 0.24603596164120567 Accuracy: 0.8945005611672279% Epoch:225\nLoss: 0.22723451422320473 Accuracy: 0.9057239057239057% Epoch:250\nLoss: 0.2204576548602846 Accuracy: 0.9023569023569024% Epoch:275\nTraining Ended\n","output_type":"stream"}]},{"cell_type":"code","source":"#test 데이터에 대한 예측 수행, 결과 파일 생성 \ntensor_test_x = torch.FloatTensor(test_x)\nwith torch.no_grad():\n    test_output = simple_nn(tensor_test_x)\n    result = np.array([1 if out >= 0.5 else 0 for out in test_output])\n    submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived' : result})\n    submission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:39:00.317881Z","iopub.execute_input":"2024-05-20T10:39:00.318839Z","iopub.status.idle":"2024-05-20T10:39:00.344447Z","shell.execute_reply.started":"2024-05-20T10:39:00.318800Z","shell.execute_reply":"2024-05-20T10:39:00.343005Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}