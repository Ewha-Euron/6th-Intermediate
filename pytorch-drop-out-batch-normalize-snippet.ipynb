{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\ntrain = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\nsubmission = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-19T13:28:13.710188Z","iopub.execute_input":"2024-05-19T13:28:13.711038Z","iopub.status.idle":"2024-05-19T13:28:13.776304Z","shell.execute_reply.started":"2024-05-19T13:28:13.710909Z","shell.execute_reply":"2024-05-19T13:28:13.774780Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SimpleNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.classifier = nn.Sequential(\n            nn.Linear(5, 128),\n            ## Batch Normalization between 'Layer' and 'Activation function'\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            ## Drop out after 'Activation function'\n            nn.Dropout(0.1),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:28:22.073366Z","iopub.execute_input":"2024-05-19T13:28:22.073781Z","iopub.status.idle":"2024-05-19T13:28:23.823399Z","shell.execute_reply.started":"2024-05-19T13:28:22.073745Z","shell.execute_reply":"2024-05-19T13:28:23.822096Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_set = pd.concat((train.drop(['Survived'], axis = 1), test), axis = 0)\n\ndata_set = data_set.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis = 1)\ndata_set = data_set.fillna(data_set.mean())\n\nn_train = train.shape[0]\ntrain_x, test_x = data_set[:n_train], data_set[n_train:]\ntrain_y = train['Survived']\n\ntrain_x = train_x[train_x.keys()].values\ntest_x = test_x[test_x.keys()].values\ntrain_y = train_y.values\n\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nsimple_nn = SimpleNN()\noptimizer = optim.Adam(simple_nn.parameters(), lr=0.01)\nerror = nn.BCELoss()\n\nbatch_size = 99\nbatch_count = int(len(train_x) / batch_size)\n\nfor epoch in range(300):\n    train_loss = 0\n    num_right = 0\n    for i in range(batch_count):\n        start = i * batch_size\n        end = start + batch_size\n        tensor_x = torch.FloatTensor(train_x[start:end])\n        tensor_y = torch.FloatTensor(train_y[start:end]).reshape(-1, 1)\n        \n        optimizer.zero_grad()\n        output = simple_nn(tensor_x)\n        loss = error(output, tensor_y)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * batch_size\n        result = [1 if out >= 0.5 else 0 for out in output]\n        num_right += np.sum(np.array(result) == train_y[start:end])\n        \n    train_loss = train_loss / len(train_x)\n    accuracy = num_right / len(train_x)\n    \n    if epoch % 25 == 0:\n        print('Loss: {} Accuracy: {}% Epoch:{}'.format(train_loss, accuracy, epoch))\n\nprint('Training Ended')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:28:28.375338Z","iopub.execute_input":"2024-05-19T13:28:28.376137Z","iopub.status.idle":"2024-05-19T13:28:42.185339Z","shell.execute_reply.started":"2024-05-19T13:28:28.376053Z","shell.execute_reply":"2024-05-19T13:28:42.184007Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Loss: 0.6514064603381686 Accuracy: 0.6464646464646465% Epoch:0\nLoss: 0.5209113558133444 Accuracy: 0.7474747474747475% Epoch:25\nLoss: 0.46819742189513314 Accuracy: 0.7777777777777778% Epoch:50\nLoss: 0.4187476866775089 Accuracy: 0.8013468013468014% Epoch:75\nLoss: 0.3799755871295929 Accuracy: 0.8338945005611672% Epoch:100\nLoss: 0.3358530220058229 Accuracy: 0.8428731762065096% Epoch:125\nLoss: 0.3056807965040207 Accuracy: 0.8641975308641975% Epoch:150\nLoss: 0.3164788583914439 Accuracy: 0.8630751964085297% Epoch:175\nLoss: 0.2507173286543952 Accuracy: 0.8810325476992144% Epoch:200\nLoss: 0.28269079162014854 Accuracy: 0.8810325476992144% Epoch:225\nLoss: 0.27201805346541935 Accuracy: 0.8900112233445566% Epoch:250\nLoss: 0.2591233518388536 Accuracy: 0.8911335578002245% Epoch:275\nTraining Ended\n","output_type":"stream"}]},{"cell_type":"code","source":"tensor_test_x = torch.FloatTensor(test_x)\nwith torch.no_grad():\n    test_output = simple_nn(tensor_test_x)\n    result = np.array([1 if out >= 0.5 else 0 for out in test_output])\n    submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': result})\n    submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T13:28:53.609723Z","iopub.execute_input":"2024-05-19T13:28:53.610511Z","iopub.status.idle":"2024-05-19T13:28:53.628024Z","shell.execute_reply.started":"2024-05-19T13:28:53.610467Z","shell.execute_reply":"2024-05-19T13:28:53.626806Z"},"trusted":true},"execution_count":6,"outputs":[]}]}