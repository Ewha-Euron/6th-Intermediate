# 1. 머신러닝 어플리케이션 설정하기
## 1-1. Train/Dev/Test 세트
__훈련 세트(train set)__ : 훈련을 위해 사용되는 데이터

__개발 세트(dev set)__ : 다양한 모델 중 어떤 모델이 좋은 성능 나타내는지 확인

__테스트 세트(test set)__ : 모델이 얼마나 잘 작동하는지 확인, 목표: 최종 데이터의 성능에 대한 비편향 추정 제

Previous era:70%,30%,30% 혹은 60%,20%,20% 비율로 나눔

현재(Big data): 98%,1%,1%비율로, 1,000,000이상일 때는 99.5%,0.25%,0.25% 혹은 99.5%,0.4%,0.1% 비율로 나눔

## 1-2. 편향/분산
가정: Bayes error(베이지안 최적 오차) 작고, train과 dev set이 같은 확률 분포

Train set error: 편향(Bias)문제 있는지 , 훈련 데이터에서 얼마나 알고리즘이 적합한지

train set error에서 dev set error로 갈 때 오차 얼마나 커지는지: 분산(Variance) 문제 얼마나 나쁜지

![편향-분산 트레이드오프](https://cphinf.pstatic.net/mooc/20180622_15/15296475860681FH70_PNG/1.PNG)

## 1-3. 머신러닝을 위한 기본 레시피

![recipe](https://cphinf.pstatic.net/mooc/20180622_162/1529647803321yYtQt_PNG/image.PNG)

# 2. 신경망 네트워크의 정규화

## 2-1. 정규화
높은 분산으로 신경망이 데이터를 과적합하는 문제가 의심되면 가장 처음 시도해봐야 할 것

L2 정규화=가중치 감쇠(weight decay)

![2-1](https://github.com/seoyeonkim3/Euron-Intermediate-study/blob/Week6/images/2-1.png?raw=true)

## 2-2. 왜 정규화는 과대적합을 줄일 수 있을까요?

정규화 매개변수↑ → 매개변수 w↓ → z↓(b 효과 무시) → tanh (비교적) 선형 → 과대적합 가능성↓

![2-2](https://github.com/seoyeonkim3/Euron-Intermediate-study/blob/Week6/images/2-2.png?raw=true)

## 2-3. 드롭아웃 정규화
__드롭아웃(Dropout)__: 신경망의 각각의 층에 대해 노드를 삭제하는 확률 설정

삭제할 노드를 랜덤으로 선정 후 삭제된 노드의 들어가는 링크와 나가는 링크를 모두 삭제 → 더 작은 네트워크로 훈련

__역 드롭아웃(Inverted Dropout)__: 노드를 삭제후에 얻은 활성화 값에 keep.prop(삭제하지 않을 확률)을 나눠 주는 것

∵기존에 삭제하지 않았을 때 활성화 값의 기대값으로 맞춰주기 위함

## 2-4. 드롭아웃의 이해
랜덤으로 노드를 삭제 시키기 때문에, 하나의 특성에 의존 하지 못하게 만듦 → 가중치를 다른 곳으로 분산 시키는 효과

드롭아웃의 keep.prob 확률은 층마다 다르게 설정 가능: 과대 적합 확률 큰 층에 더 낮은 keep.prob 설정

단점: 모든 반복에서 잘 정의된 비용함수가 하강하는지 확인 어려움 → keep_probs=1로 설정해서 J 단소감소하는지 확인

## 2-5. 다른 정규화 방법들
- 데이터증식(Data augmentation): 이미지를 대칭, 확대, 왜곡 혹은 회전 시켜서 새로운 훈련 데이터 생성

- 조기종료(Early stopping): 신경망이 개발 세트의 오차 저점 부근, 즉 가장 잘 작동하는 점일때 훈련을 멈추는 것

    - 단점: 훈련시 훈련 목적인 비용 함수를 최적화 시키는 작업과 과대적합하지 않게 만드는 작업을 섞음 → 최적의 조건을 찾지 못할 수도 
