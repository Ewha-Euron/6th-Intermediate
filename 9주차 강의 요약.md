# 딥러닝 2단계: 심층 신경망 성능 향상시키기
## 3. 최적화 문제 설정
### 3-1. 입력값의 정규화(normalizing inputs)
- 입력 특성이 매우 다른 크기(범위)를 가지면, 정규화(normalizing)하는 것이 중요

![정규화 방법](https://github.com/seoyeonkim3/Euron-Intermediate-study/blob/Week9/images/3-1.%20%EC%A0%95%EA%B7%9C%ED%99%94%20%EB%B0%A9%EB%B2%95.png?raw=true)

- 테스트 세트 정규화할 때, 훈련 데이터에 사용한 μ,σ 를 사용
- 정규화를 통해 비용함수의 모양은 대칭적이고 더 둥글고 최적화하기 쉬운 모습이 됨 → 알고리즘 빨리 실행

### 3-2. 경사소실/경사폭발(vanishing/exploding gradients)
- 매우 깊은 신경망을 훈련시킬 때 나타나는 문제
- w(가중치 행렬) > I(단위 행렬) → 경사의 폭발(exploding gradients) 문제 발생
  
  w(가중치 행렬) < I(단위 행렬) → 경사의 소실(vanishing gradients) 문제 발생
- 경사의 소실과 폭발로 인해 학습 시키는데 많은 시간이 걸리므로, 가중치 초기화 값을 신중히 설정해야 함

### 3-3. 심층 신경망의 가중치 초기화(weight initialization for deep networks)
- 아주 깊은 신경망에서 존재하는 경사 소실과 폭발의 문제 해결에 많은 도움을 주는 해결법: 신경망에 대한 무작위의 초기화를 더 신중하게 선택

![가중치 초기화 방법](https://github.com/seoyeonkim3/Euron-Intermediate-study/blob/Week9/images/3-3.%20%EA%B0%80%EC%A4%91%EC%B9%98%20%EC%B4%88%EA%B8%B0%ED%99%94%20%EB%B0%A9%EB%B2%95.png?raw=true)

### 3-4. 기울기의 수치 근사(numerical approximation of gradients)
- 경사 검사(gradient checking) 이용 목적: 역전파를 알맞게 구현했는지 확인
- 한 쪽의 차이보다는 양쪽의 차이에 관한 수식을 사용하는 것이 더 정확

![중심 차분법의 정의](https://github.com/seoyeonkim3/Euron-Intermediate-study/blob/Week9/images/3-4.%20%EC%A4%91%EC%8B%AC%20%EC%B0%A8%EB%B6%84%EB%B2%95%EC%9D%98%20%EC%A0%95%EC%9D%98.png?raw=true)

### 3-5. 경사 검사(gradient checking)
- 모델 안에 있는 모든 변수(W, b)를 하나의 벡터(θ)로 concatenate: 비용 함수 J(W, b) → J( θ )

![3-5](https://github.com/seoyeonkim3/Euron-Intermediate-study/blob/Week9/images/3-5..png?raw=true)

### 3-6. 경사 검사 시 주의할 점(gradient checking implementation notes)
- 속도가 굉장히 느려지므로 훈련시에는 절대 사용 하지 않고, 디버깅 할때만 사용하
- 알고리즘이 경사 검사에 실패 했다면(dθapprox가 dθ에서 매우 먼 경우), 어느 원소 부분에서 실패했는지 찾아보기
  특정 부분에서 계속 실패했다면, 그 경사가 계산된 층에서 문제가 생긴것을 확인 가능
- dθ는 θ에 대응하는 J의 정규화 항도 포함하므로, 경사 검사 계산시 같이 포함하기
- 드롭아웃에서는 무작위로 노드를 삭제하기 때문에 적용하기 쉽지 않으므로, 드롭아웃을 끄고 알고리즘이 최소한 드롭아웃 없이 맞는지 확인한 후 다시 드롭아웃을 켜기
- 무작위 초기화를 해도 초기에 경사 검사가 잘 되는 경우, 훈련을 조금 시킨 다음에 경사 검사를 다시 해보기 (거의 일어나지 않지 경우임)
